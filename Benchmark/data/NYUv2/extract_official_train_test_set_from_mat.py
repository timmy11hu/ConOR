#!/usr/bin/env python
# -*- coding: utf-8 -*-
#######################################################################################
# The MIT License

# Copyright (c) 2014       Hannes Schulz, University of Bonn  <schulz@ais.uni-bonn.de>
# Copyright (c) 2013       Benedikt Waldvogel, University of Bonn <mail@bwaldvogel.de>
# Copyright (c) 2008-2009  Sebastian Nowozin                       <nowozin@gmail.com>

# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#######################################################################################
#
# Helper script to convert the NYU Depth v2 dataset Matlab file into a set of
# PNG and JPEG images.
#
# See https://github.com/deeplearningais/curfil/wiki/Training-and-Prediction-with-the-NYU-Depth-v2-Dataset

from __future__ import print_function

import h5py
import numpy as np
import os
import scipy.io
import sys
import cv2


def convert_image(i, scene, depth_raw, image):

    idx = int(i) + 1
    if idx in train_images:
        train_test = "train"
    else:
        assert idx in test_images, "index %d neither found in training set nor in test set" % idx
        train_test = "test"

    folder = "%s/%s/%s" % (out_folder, train_test, scene)
    if not os.path.exists(folder):
        os.makedirs(folder)

    img_depth = depth_raw * 1000.0
    img_depth_uint16 = img_depth.astype(np.uint16)
    cv2.imwrite("%s/sync_depth_%05d.png" % (folder, i), img_depth_uint16)
    image = image[:, :, ::-1]
    image_black_boundary = np.zeros((480, 640, 3), dtype=np.uint8)
    image_black_boundary[7:474, 7:632, :] = image[7:474, 7:632, :]
    cv2.imwrite("%s/rgb_%05d.jpg" % (folder, i), image_black_boundary)


if __name__ == "__main__":

    if len(sys.argv) < 4:
        print("usage: %s <h5_file> <train_test_split> <out_folder>" % sys.argv[0], file=sys.stderr)
        sys.exit(0)

    h5_file = h5py.File(sys.argv[1], "r")
    # h5py is not able to open that file. but scipy is
    train_test = scipy.io.loadmat(sys.argv[2])
    out_folder = sys.argv[3]

    test_images = set([int(x) for x in train_test["testNdxs"]])
    train_images = set([int(x) for x in train_test["trainNdxs"]])
    print("%d training images" % len(train_images))
    print("%d test images" % len(test_images))

    depth_raw = h5_file['rawDepths']

    rgb_filenames = [u''.join(chr(c[0]) for c in h5_file[obj_ref]) for obj_ref in h5_file['rawRgbFilenames'][0]]
    depth_filenames = [u''.join(chr(c[0]) for c in h5_file[obj_ref]) for obj_ref in h5_file['rawDepthFilenames'][0]]

    print("reading", sys.argv[1])

    images = h5_file['images']
    scenes = [u''.join(chr(c[0]) for c in h5_file[obj_ref]) for obj_ref in h5_file['sceneTypes'][0]]
    scene_list = [u''.join(chr(c[0]) for c in h5_file[obj_ref]) for obj_ref in h5_file['scenes'][0]]

    # scene_list = [f.split('/')[0] for f in rgb_filenames]
    for i, scene_name in enumerate(scene_list):
        f1 = rgb_filenames[i]
        f2 = depth_filenames[i]
        assert f1.split('/')[0] == f2.split('/')[0]
        if f2.split('/')[0] != scene_name and f2.split('/')[0][:-1] != scene_name:
            print(scene_name)
            print(f2.split('/')[0])
            print()
    exit()

    train_scene = []
    for i in train_images:
        sss = scene_list[i-1]
        if sss not in set(train_scene):
            train_scene.append(sss)
    print(len(set(train_scene)))
    test_scene = []
    for i in test_images:
        sss = scene_list[i - 1]
        if sss not in set(test_scene):
            test_scene.append(sss)
    print(len(set(test_scene)))
    out_dict = {
        'train': train_scene,
        'test': test_scene
    }
    # train_scene.sort()
    # for e in train_scene:
    #     print(e)
    # print()
    # test_scene.sort()
    # for e in test_scene:
    #     print(e)
    # import json
    # with open('scene_split_dict2.json', 'w') as f:
    #     json.dump(out_dict, f)

    exit()

    # print("processing images")
    # for i, image in enumerate(images):
    #     print("image", i + 1, "/", len(images))
    #     convert_image(i, scenes[i], depth_raw[i, :, :].T, image.T)
    #
    # print("Finished")